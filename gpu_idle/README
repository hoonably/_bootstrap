# gpu_idle_runner.py

A lightweight GPU activity monitor that automatically runs short dummy workloads to keep GPUs from being reclaimed when idle.

---

## üß© Overview

* On first launch, it triggers a 1-minute dummy load after **1 minute of idle time**.
* Then, it monitors all GPUs continuously and every **59 minutes of full idleness (`util=0%`)**,
  it runs a **1-minute dummy workload** to keep the GPU active.
* Prints a concise one-line summary per GPU every **5 seconds**.

---

## ‚öôÔ∏è Environment Setup

### 1. Install dependencies

```bash
# PyTorch (CUDA 12.1 example)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121

# Numpy
pip install numpy

# Optional: setproctitle for cleaner process titles
pip install setproctitle
```

### 2. (Optional) Install tmux

```bash
sudo apt-get update
sudo apt-get install tmux
tmux -V
```

---

## üöÄ Usage

### Run in background via tmux

Start a detached session named `dummy` and run the script:

```bash
tmux new -d -s dummy "python gpu_idle_runner.py"
```

### Adjust idle / polling / workload time

```bash
# Example: trigger after 20 min idle, poll every 15 s, run dummy for 3 min
python gpu_idle_runner.py --idle-min 20 --poll-sec 15 --minutes 3
```

### Manually test a worker on a specific GPU

```bash
python gpu_idle_runner.py --worker --gpu-id 0 --minutes 1
```

---

## üß† Notes

* Default behavior:

  * Polling interval: **5 s**
  * Idle threshold: **59 min** (first trigger 1 min)
  * Dummy workload duration: **1 min**
* Uses `nvidia-smi` for GPU utilization queries.
* The worker uses small PyTorch convolution layers to generate light load.
* Logs update every 5 seconds with one summary line per GPU.
* Safe to stop anytime with `Ctrl+C` or by killing the tmux session:

  ```bash
  tmux kill-session -t dummy
  ```
* Works on systems with multiple GPUs; each GPU is monitored independently.
